{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_map(x: int) -> int:\n",
    "    x = int(x)\n",
    "    if x < 20:\n",
    "        return 1\n",
    "    elif x >= 20 and x < 30:\n",
    "        return 2\n",
    "    elif x >= 30 and x < 40:\n",
    "        return 3\n",
    "    elif x >= 40 and x < 50:\n",
    "        return 4\n",
    "    elif x >= 50 and x < 60:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/opt/ml/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(data_path + 'users.csv')\n",
    "books = pd.read_csv(data_path + 'books.csv')\n",
    "train = pd.read_csv(data_path + 'train_ratings.csv')\n",
    "test = pd.read_csv(data_path + 'test_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mission_1_EDA(users, books):\n",
    "    print('-'*20, 'Mission1 EDA Start', '-'*20)\n",
    "    # user preprocessing\n",
    "    users['location_city'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "    users['location_city'] = users['location'].apply(lambda x: x.split(',')[0])\n",
    "    users['location_state'] = users['location'].apply(lambda x: x.split(',')[1])\n",
    "    users['location_country'] = users['location'].apply(lambda x: x.split(',')[2])\n",
    "    users = users.replace('na', np.nan) #특수문자 제거로 n/a가 na로 바뀌게 되었습니다. 따라서 이를 컴퓨터가 인식할 수 있는 결측값으로 변환합니다.\n",
    "    users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "    \n",
    "\n",
    "    # city는 있는데 country 없는 경우 채우기\n",
    "    modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "\n",
    "    location_list = []\n",
    "    for location in tqdm(modify_location, desc='preprocessing...(1/4)'):\n",
    "        try:\n",
    "            right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "            location_list.append(right_location)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for location in tqdm(location_list, desc='preprocessing...(2/4)'):\n",
    "        users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "        users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]\n",
    "\n",
    "    # book preprocessing\n",
    "\n",
    "    # 유명 출판사 표기 오류로 그룹화되지 못하는 케이스 처리\n",
    "    publisher_dict=(books['publisher'].value_counts()).to_dict()\n",
    "    publisher_count_df = pd.DataFrame(list(publisher_dict.items()),columns = ['publisher','count'])\n",
    "    publisher_count_df = publisher_count_df.sort_values(by=['count'], ascending = False)\n",
    "\n",
    "    modify_list = publisher_count_df[publisher_count_df['count']>1].publisher.values\n",
    "\n",
    "    for publisher in tqdm(modify_list, desc='preprocessing...(3/4)'):\n",
    "        try:\n",
    "            number = books[books['publisher']==publisher]['isbn'].apply(lambda x: x[:4]).value_counts().index[0]\n",
    "            right_publisher = books[books['isbn'].apply(lambda x: x[:4])==number]['publisher'].value_counts().index[0]\n",
    "            books.loc[books[books['isbn'].apply(lambda x: x[:4])==number].index,'publisher'] = right_publisher\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "    # category 대괄호 제거 및 소문자 변환\n",
    "    books.loc[books[books['category'].notnull()].index, 'category'] = books[books['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "    books['category'] = books['category'].str.lower()\n",
    "\n",
    "    # 43개의 high-category로 묶기\n",
    "    categories = ['garden','crafts','physics','adventure','music','fiction','nonfiction','science','science fiction','social','homicide',\n",
    "                  'sociology','disease','religion','christian','philosophy','psycholog','mathemat','agricult','environmental',\n",
    "                  'business','poetry','drama','literary','travel','motion picture','children','cook','literature','electronic',\n",
    "                  'humor','animal','bird','photograph','computer','house','ecology','family','architect','camp','criminal','language','india']\n",
    "\n",
    "    for category in tqdm(categories, desc='preprocessing...(4/4)'):\n",
    "        books.loc[books[books['category'].str.contains(category,na=False)].index,'category_high'] = category\n",
    "\n",
    "    # 5개 이하 항목 others로 묶기\n",
    "    category_high_df = pd.DataFrame(books['category_high'].value_counts()).reset_index()\n",
    "    category_high_df.columns = ['category','count']\n",
    "    others_list = category_high_df[category_high_df['count']<5]['category'].values\n",
    "    books.loc[books[books['category_high'].isin(others_list)].index, 'category_high']='others'\n",
    "\n",
    "    # location은 이제 필요 없음\n",
    "    users = users.drop(['location'], axis=1)\n",
    "    print('-'*20, 'Mission1 EDA Done', '-'*20)\n",
    "    return users, books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Mission1 EDA Start --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing...(1/4): 100%|██████████| 2097/2097 [00:56<00:00, 37.35it/s]\n",
      "preprocessing...(2/4): 100%|██████████| 1948/1948 [00:18<00:00, 103.56it/s]\n",
      "preprocessing...(3/4): 100%|██████████| 5276/5276 [02:28<00:00, 35.60it/s]\n",
      "preprocessing...(4/4): 100%|██████████| 43/43 [00:02<00:00, 19.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Mission1 EDA Done --------------------\n"
     ]
    }
   ],
   "source": [
    "users_eda, books_eda = mission_1_EDA(users, books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "# 인덱싱 처리된 데이터 조인\n",
    "context_df = ratings.merge(users_eda, on='user_id', how='left').merge(books_eda[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')\n",
    "train_df = train.merge(users_eda, on='user_id', how='left').merge(books_eda[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')\n",
    "test_df = test.merge(users_eda, on='user_id', how='left').merge(books_eda[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱싱 처리\n",
    "loc_city2idx = {v:k for k,v in enumerate(context_df['location_city'].unique())}\n",
    "loc_state2idx = {v:k for k,v in enumerate(context_df['location_state'].unique())}\n",
    "loc_country2idx = {v:k for k,v in enumerate(context_df['location_country'].unique())}\n",
    "\n",
    "train_df['location_city'] = train_df['location_city'].map(loc_city2idx)\n",
    "train_df['location_state'] = train_df['location_state'].map(loc_state2idx)\n",
    "train_df['location_country'] = train_df['location_country'].map(loc_country2idx)\n",
    "test_df['location_city'] = test_df['location_city'].map(loc_city2idx)\n",
    "test_df['location_state'] = test_df['location_state'].map(loc_state2idx)\n",
    "test_df['location_country'] = test_df['location_country'].map(loc_country2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306795, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76699, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_city = context_df[['location_city', 'age']].copy()\n",
    "context_city['location_city'] = context_city['location_city'].map(loc_city2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_replace_idx = np.where(context_city.groupby('location_city')['age'].count() > 1)[0]\n",
    "age_replace = context_city.groupby('location_city')['age'].median()[age_replace_idx]\n",
    "age_replace_df = pd.DataFrame({'location_city':age_replace.index, 'age_fillna':age_replace.values})\n",
    "\n",
    "train_df = train_df.merge(age_replace_df, on='location_city', how='left')\n",
    "train_df = train_df.drop(columns='age').rename(columns={'age_fillna':'age'})\n",
    "train_df['age'] = train_df['age'].fillna(int(train_df['age'].mean()))\n",
    "train_df['age'] = train_df['age'].apply(age_map)\n",
    "\n",
    "test_df = test_df.merge(age_replace_df, on='location_city', how='left')\n",
    "test_df = test_df.drop(columns='age').rename(columns={'age_fillna':'age'})\n",
    "test_df['age'] = test_df['age'].fillna(int(test_df['age'].mean()))\n",
    "test_df['age'] = test_df['age'].apply(age_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306795, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
