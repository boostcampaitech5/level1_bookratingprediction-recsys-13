{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "books = pd.read_csv('/opt/ml/data/books.csv')\n",
    "users = pd.read_csv('/opt/ml/data/users.csv')\n",
    "ratings = pd.read_csv('/opt/ml/data/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "['Fiction']                                               32956\n",
       "['Juvenile Fiction']                                       5804\n",
       "['Biography & Autobiography']                              3320\n",
       "['History']                                                1925\n",
       "['Religion']                                               1818\n",
       "                                                          ...  \n",
       "['Disguise']                                                  1\n",
       "['Country lawyers']                                           1\n",
       "['Humorous stories, Brazilian']                               1\n",
       "['Coasts']                                                    1\n",
       "['Authors, Canadian (English) 20th century Biography']        1\n",
       "Name: count, Length: 4292, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.loc[books['category'].notnull()]['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                   0.000000\n",
       "book_title             0.000000\n",
       "book_author            0.000007\n",
       "year_of_publication    0.000000\n",
       "publisher              0.000000\n",
       "img_url                0.000000\n",
       "language               0.449468\n",
       "category               0.460326\n",
       "summary                0.449468\n",
       "img_path               0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isna().sum()/len(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.loc[books[books['category'].notnull()].index, 'category'] = books[books['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "publisher_dict=(books['publisher'].value_counts()).to_dict()\n",
    "publisher_count_df= pd.DataFrame(list(publisher_dict.items()),columns = ['publisher','count'])\n",
    "publisher_count_df = publisher_count_df.sort_values(by=['count'], ascending = False)\n",
    "modify_list = publisher_count_df[publisher_count_df['count']>1].publisher.values\n",
    "for publisher in modify_list:\n",
    "    try:\n",
    "        number = books[books['publisher']==publisher]['isbn'].apply(lambda x: x[:4]).value_counts().index[0]\n",
    "        right_publisher = books[books['isbn'].apply(lambda x: x[:4])==number]['publisher'].value_counts().index[0]\n",
    "        books.loc[books[books['isbn'].apply(lambda x: x[:4])==number].index,'publisher'] = right_publisher\n",
    "    except: \n",
    "        pass\n",
    "books['publisher'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['category'] = books['category'].str.lower()\n",
    "categories = ['garden','crafts','physics','adventure','music','fiction','nonfiction','science','science fiction','social','homicide',\n",
    " 'sociology','disease','religion','christian','philosophy','psycholog','mathemat','agricult','environmental',\n",
    " 'business','poetry','drama','literary','travel','motion picture','children','cook','literature','electronic',\n",
    " 'humor','animal','bird','photograph','computer','house','ecology','family','architect','camp','criminal','language','india']\n",
    "\n",
    "for category in categories:\n",
    "    books.loc[books[books['category'].str.contains(category,na=False)].index,'category'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fiction</th>\n",
       "      <td>41264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biography autobiography</th>\n",
       "      <td>3326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>1826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humor</th>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cook</th>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body mind spirit</th>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health fitness</th>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>literary</th>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poetry</th>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psycholog</th>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self help</th>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count\n",
       "category                      \n",
       "fiction                  41264\n",
       "biography autobiography   3326\n",
       "science                   2308\n",
       "history                   1927\n",
       "religion                  1826\n",
       "humor                     1289\n",
       "business                  1147\n",
       "cook                      1125\n",
       "body mind spirit          1113\n",
       "family                     988\n",
       "health fitness             971\n",
       "literary                   848\n",
       "computer                   819\n",
       "language                   785\n",
       "poetry                     779\n",
       "psycholog                  719\n",
       "travel                     672\n",
       "self help                  640\n",
       "art                        563\n",
       "drama                      537"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isna().sum()\n",
    "count_category_df = pd.DataFrame(books['category'].value_counts())\n",
    "count_category_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophy</th>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nature</th>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference</th>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performing arts</th>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyster industry</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>african american artists</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarek fictitious character</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gorilla</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authors canadian english 20th century biography</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 count\n",
       "category                                              \n",
       "children                                           516\n",
       "philosophy                                         491\n",
       "nature                                             490\n",
       "reference                                          471\n",
       "performing arts                                    457\n",
       "...                                                ...\n",
       "oyster industry                                      1\n",
       "african american artists                             1\n",
       "sarek fictitious character                           1\n",
       "gorilla                                              1\n",
       "authors canadian english 20th century biography      1\n",
       "\n",
       "[3248 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_category_df[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Collins</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>actresses</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Perennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>1940 1949</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>images/0060973129.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>medical</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "      <td>images/0374157065.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>A Chinese immigrant who is convinced she is dy...</td>\n",
       "      <td>images/0399135782.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>history</td>\n",
       "      <td>Essays by respected military historians, inclu...</td>\n",
       "      <td>images/0425176428.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149562</th>\n",
       "      <td>0670528951</td>\n",
       "      <td>Orson Welles</td>\n",
       "      <td>Barbara Leaming</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Viking Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0670528951.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>biography autobiography</td>\n",
       "      <td>Based on two years of interviews and research,...</td>\n",
       "      <td>images/0670528951.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149563</th>\n",
       "      <td>0689818904</td>\n",
       "      <td>My Grandmother's Journey</td>\n",
       "      <td>John Cech</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Aladdin</td>\n",
       "      <td>http://images.amazon.com/images/P/0689818904.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>A grandmother tells the story of her eventful ...</td>\n",
       "      <td>images/0689818904.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149565</th>\n",
       "      <td>067161746X</td>\n",
       "      <td>The Bachelor Home Companion: A Practical Guide...</td>\n",
       "      <td>P.J. O'Rourke</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>http://images.amazon.com/images/P/067161746X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>humor</td>\n",
       "      <td>A tongue-in-cheek survival guide for single pe...</td>\n",
       "      <td>images/067161746X.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149566</th>\n",
       "      <td>0767907566</td>\n",
       "      <td>All Elevations Unknown: An Adventure in the He...</td>\n",
       "      <td>Sam Lightner</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Broadway Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0767907566.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>nature</td>\n",
       "      <td>A daring twist on the travel-adventure genre t...</td>\n",
       "      <td>images/0767907566.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149568</th>\n",
       "      <td>0912333022</td>\n",
       "      <td>The Are You Being Served? Stories: 'Camping In...</td>\n",
       "      <td>Jeremy Lloyd</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Pub Group West</td>\n",
       "      <td>http://images.amazon.com/images/P/0912333022.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>These hilarious stories by the creator of publ...</td>\n",
       "      <td>images/0912333022.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80719 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              isbn                                         book_title   \n",
       "0       0002005018                                       Clara Callan  \\\n",
       "1       0060973129                               Decision in Normandy   \n",
       "2       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "3       0399135782                             The Kitchen God's Wife   \n",
       "4       0425176428  What If?: The World's Foremost Military Histor...   \n",
       "...            ...                                                ...   \n",
       "149562  0670528951                                       Orson Welles   \n",
       "149563  0689818904                           My Grandmother's Journey   \n",
       "149565  067161746X  The Bachelor Home Companion: A Practical Guide...   \n",
       "149566  0767907566  All Elevations Unknown: An Adventure in the He...   \n",
       "149568  0912333022  The Are You Being Served? Stories: 'Camping In...   \n",
       "\n",
       "                 book_author  year_of_publication                 publisher   \n",
       "0       Richard Bruce Wright               2001.0                   Collins  \\\n",
       "1               Carlo D'Este               1991.0                 Perennial   \n",
       "2           Gina Bari Kolata               1999.0      Farrar Straus Giroux   \n",
       "3                    Amy Tan               1991.0          Putnam Pub Group   \n",
       "4              Robert Cowley               2000.0  Berkley Publishing Group   \n",
       "...                      ...                  ...                       ...   \n",
       "149562       Barbara Leaming               1985.0              Viking Books   \n",
       "149563             John Cech               1998.0                   Aladdin   \n",
       "149565         P.J. O'Rourke               1987.0                    Pocket   \n",
       "149566          Sam Lightner               2001.0            Broadway Books   \n",
       "149568          Jeremy Lloyd               1997.0            Pub Group West   \n",
       "\n",
       "                                                  img_url language   \n",
       "0       http://images.amazon.com/images/P/0002005018.0...       en  \\\n",
       "1       http://images.amazon.com/images/P/0060973129.0...       en   \n",
       "2       http://images.amazon.com/images/P/0374157065.0...       en   \n",
       "3       http://images.amazon.com/images/P/0399135782.0...       en   \n",
       "4       http://images.amazon.com/images/P/0425176428.0...       en   \n",
       "...                                                   ...      ...   \n",
       "149562  http://images.amazon.com/images/P/0670528951.0...       en   \n",
       "149563  http://images.amazon.com/images/P/0689818904.0...       en   \n",
       "149565  http://images.amazon.com/images/P/067161746X.0...       en   \n",
       "149566  http://images.amazon.com/images/P/0767907566.0...       en   \n",
       "149568  http://images.amazon.com/images/P/0912333022.0...       en   \n",
       "\n",
       "                       category   \n",
       "0                     actresses  \\\n",
       "1                     1940 1949   \n",
       "2                       medical   \n",
       "3                       fiction   \n",
       "4                       history   \n",
       "...                         ...   \n",
       "149562  biography autobiography   \n",
       "149563                  fiction   \n",
       "149565                    humor   \n",
       "149566                   nature   \n",
       "149568                  fiction   \n",
       "\n",
       "                                                  summary   \n",
       "0       In a small town in Canada, Clara Callan reluct...  \\\n",
       "1       Here, for the first time in paperback, is an o...   \n",
       "2       Describes the great flu epidemic of 1918, an o...   \n",
       "3       A Chinese immigrant who is convinced she is dy...   \n",
       "4       Essays by respected military historians, inclu...   \n",
       "...                                                   ...   \n",
       "149562  Based on two years of interviews and research,...   \n",
       "149563  A grandmother tells the story of her eventful ...   \n",
       "149565  A tongue-in-cheek survival guide for single pe...   \n",
       "149566  A daring twist on the travel-adventure genre t...   \n",
       "149568  These hilarious stories by the creator of publ...   \n",
       "\n",
       "                                 img_path  \n",
       "0       images/0002005018.01.THUMBZZZ.jpg  \n",
       "1       images/0060973129.01.THUMBZZZ.jpg  \n",
       "2       images/0374157065.01.THUMBZZZ.jpg  \n",
       "3       images/0399135782.01.THUMBZZZ.jpg  \n",
       "4       images/0425176428.01.THUMBZZZ.jpg  \n",
       "...                                   ...  \n",
       "149562  images/0670528951.01.THUMBZZZ.jpg  \n",
       "149563  images/0689818904.01.THUMBZZZ.jpg  \n",
       "149565  images/067161746X.01.THUMBZZZ.jpg  \n",
       "149566  images/0767907566.01.THUMBZZZ.jpg  \n",
       "149568  images/0912333022.01.THUMBZZZ.jpg  \n",
       "\n",
       "[80719 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = books[books['category'].notnull()]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec # numpy version 1.20.3 -> 1.24.2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "books = pd.read_csv('/opt/ml/data/books.csv')\n",
    "users = pd.read_csv('/opt/ml/data/users.csv')\n",
    "ratings = pd.read_csv('/opt/ml/data/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books[books['category'].notnull()].index, 'category'] = books[books['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "books['category'] = books['category'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books[books['category'] == 'juvenile fiction'].index, \"category\"] = 'fiction'\n",
    "books.loc[books[books['category'] == 'juvenile nonfiction'].index, \"category\"] = 'nonfiction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = books[books['category'].notnull()]['book_title'], books[books['category'].notnull()]['category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fiction',\n",
       " 'biography autobiography',\n",
       " 'history',\n",
       " 'religion',\n",
       " 'nonfiction',\n",
       " 'social science',\n",
       " 'humor',\n",
       " 'body mind spirit',\n",
       " 'business economics',\n",
       " 'cooking',\n",
       " 'health fitness',\n",
       " 'family relationships',\n",
       " 'computers',\n",
       " 'travel',\n",
       " 'self help',\n",
       " 'psychology',\n",
       " 'poetry',\n",
       " 'science',\n",
       " 'art',\n",
       " 'literary criticism']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_categories = y.value_counts().head(20).index.tolist()\n",
    "top_20_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7492071440494075\n",
      "Classification Report:                           precision    recall  f1-score   support\n",
      "\n",
      "                    art       0.65      0.20      0.31       120\n",
      "biography autobiography       0.53      0.33      0.41       679\n",
      "       body mind spirit       0.73      0.34      0.46       220\n",
      "     business economics       0.58      0.39      0.46       194\n",
      "              computers       0.84      0.46      0.59       140\n",
      "                cooking       0.85      0.63      0.72       200\n",
      "   family relationships       0.54      0.32      0.40       177\n",
      "                fiction       0.77      0.98      0.87      7805\n",
      "         health fitness       0.77      0.48      0.59       204\n",
      "                history       0.52      0.28      0.36       401\n",
      "                  humor       0.69      0.21      0.32       231\n",
      "     literary criticism       0.60      0.12      0.20       103\n",
      "             nonfiction       0.70      0.15      0.25       294\n",
      "                 poetry       0.82      0.54      0.65       123\n",
      "             psychology       0.62      0.13      0.21       127\n",
      "               religion       0.64      0.43      0.52       355\n",
      "                science       0.79      0.27      0.40       127\n",
      "              self help       0.41      0.18      0.25       129\n",
      "         social science       0.30      0.08      0.13       225\n",
      "                 travel       0.72      0.27      0.39       128\n",
      "\n",
      "               accuracy                           0.75     11982\n",
      "              macro avg       0.65      0.34      0.42     11982\n",
      "           weighted avg       0.72      0.75      0.71     11982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 상위 30개의 카테고리를 대상으로 함\n",
    "top_20_categories = y.value_counts().head(20).index.tolist()\n",
    "X = X[y.isin(top_20_categories)]\n",
    "y = y[y.isin(top_20_categories)]\n",
    "\n",
    "# 데이터셋을 학습 데이터와 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 텍스트 데이터를 벡터화\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀 모델 \n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "# 모델 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "_classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report: \", _classification_report) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<89663x27249 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 438856 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X = books[~books['category'].isin(top_20_categories)]['book_title']\n",
    "_X_Vec = vectorizer.transform(_X)\n",
    "_X_Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>actresses</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>1940 1949</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>images/0060973129.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>medical</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "      <td>images/0374157065.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>A Chinese immigrant who is convinced she is dy...</td>\n",
       "      <td>images/0399135782.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>history</td>\n",
       "      <td>Essays by respected military historians, inclu...</td>\n",
       "      <td>images/0425176428.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149565</th>\n",
       "      <td>067161746X</td>\n",
       "      <td>The Bachelor Home Companion: A Practical Guide...</td>\n",
       "      <td>P.J. O'Rourke</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Pocket Books</td>\n",
       "      <td>http://images.amazon.com/images/P/067161746X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>humor</td>\n",
       "      <td>A tongue-in-cheek survival guide for single pe...</td>\n",
       "      <td>images/067161746X.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149566</th>\n",
       "      <td>0767907566</td>\n",
       "      <td>All Elevations Unknown: An Adventure in the He...</td>\n",
       "      <td>Sam Lightner</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Broadway Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0767907566.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>nature</td>\n",
       "      <td>A daring twist on the travel-adventure genre t...</td>\n",
       "      <td>images/0767907566.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149567</th>\n",
       "      <td>0884159221</td>\n",
       "      <td>Why stop?: A guide to Texas historical roadsid...</td>\n",
       "      <td>Claude Dooley</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Lone Star Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0884159221.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0884159221.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149568</th>\n",
       "      <td>0912333022</td>\n",
       "      <td>The Are You Being Served? Stories: 'Camping In...</td>\n",
       "      <td>Jeremy Lloyd</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Kqed Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0912333022.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>These hilarious stories by the creator of publ...</td>\n",
       "      <td>images/0912333022.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149569</th>\n",
       "      <td>1569661057</td>\n",
       "      <td>Dallas Street Map Guide and Directory, 2000 Ed...</td>\n",
       "      <td>Mapsco</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>American Map Corporation</td>\n",
       "      <td>http://images.amazon.com/images/P/1569661057.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1569661057.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149570 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              isbn                                         book_title   \n",
       "0       0002005018                                       Clara Callan  \\\n",
       "1       0060973129                               Decision in Normandy   \n",
       "2       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "3       0399135782                             The Kitchen God's Wife   \n",
       "4       0425176428  What If?: The World's Foremost Military Histor...   \n",
       "...            ...                                                ...   \n",
       "149565  067161746X  The Bachelor Home Companion: A Practical Guide...   \n",
       "149566  0767907566  All Elevations Unknown: An Adventure in the He...   \n",
       "149567  0884159221  Why stop?: A guide to Texas historical roadsid...   \n",
       "149568  0912333022  The Are You Being Served? Stories: 'Camping In...   \n",
       "149569  1569661057  Dallas Street Map Guide and Directory, 2000 Ed...   \n",
       "\n",
       "                 book_author  year_of_publication                 publisher   \n",
       "0       Richard Bruce Wright               2001.0     HarperFlamingo Canada  \\\n",
       "1               Carlo D'Este               1991.0           HarperPerennial   \n",
       "2           Gina Bari Kolata               1999.0      Farrar Straus Giroux   \n",
       "3                    Amy Tan               1991.0          Putnam Pub Group   \n",
       "4              Robert Cowley               2000.0  Berkley Publishing Group   \n",
       "...                      ...                  ...                       ...   \n",
       "149565         P.J. O'Rourke               1987.0              Pocket Books   \n",
       "149566          Sam Lightner               2001.0            Broadway Books   \n",
       "149567         Claude Dooley               1985.0           Lone Star Books   \n",
       "149568          Jeremy Lloyd               1997.0                Kqed Books   \n",
       "149569                Mapsco               1999.0  American Map Corporation   \n",
       "\n",
       "                                                  img_url language   category   \n",
       "0       http://images.amazon.com/images/P/0002005018.0...       en  actresses  \\\n",
       "1       http://images.amazon.com/images/P/0060973129.0...       en  1940 1949   \n",
       "2       http://images.amazon.com/images/P/0374157065.0...       en    medical   \n",
       "3       http://images.amazon.com/images/P/0399135782.0...       en    fiction   \n",
       "4       http://images.amazon.com/images/P/0425176428.0...       en    history   \n",
       "...                                                   ...      ...        ...   \n",
       "149565  http://images.amazon.com/images/P/067161746X.0...       en      humor   \n",
       "149566  http://images.amazon.com/images/P/0767907566.0...       en     nature   \n",
       "149567  http://images.amazon.com/images/P/0884159221.0...      NaN        NaN   \n",
       "149568  http://images.amazon.com/images/P/0912333022.0...       en    fiction   \n",
       "149569  http://images.amazon.com/images/P/1569661057.0...      NaN        NaN   \n",
       "\n",
       "                                                  summary   \n",
       "0       In a small town in Canada, Clara Callan reluct...  \\\n",
       "1       Here, for the first time in paperback, is an o...   \n",
       "2       Describes the great flu epidemic of 1918, an o...   \n",
       "3       A Chinese immigrant who is convinced she is dy...   \n",
       "4       Essays by respected military historians, inclu...   \n",
       "...                                                   ...   \n",
       "149565  A tongue-in-cheek survival guide for single pe...   \n",
       "149566  A daring twist on the travel-adventure genre t...   \n",
       "149567                                                NaN   \n",
       "149568  These hilarious stories by the creator of publ...   \n",
       "149569                                                NaN   \n",
       "\n",
       "                                 img_path  \n",
       "0       images/0002005018.01.THUMBZZZ.jpg  \n",
       "1       images/0060973129.01.THUMBZZZ.jpg  \n",
       "2       images/0374157065.01.THUMBZZZ.jpg  \n",
       "3       images/0399135782.01.THUMBZZZ.jpg  \n",
       "4       images/0425176428.01.THUMBZZZ.jpg  \n",
       "...                                   ...  \n",
       "149565  images/067161746X.01.THUMBZZZ.jpg  \n",
       "149566  images/0767907566.01.THUMBZZZ.jpg  \n",
       "149567  images/0884159221.01.THUMBZZZ.jpg  \n",
       "149568  images/0912333022.01.THUMBZZZ.jpg  \n",
       "149569  images/1569661057.01.THUMBZZZ.jpg  \n",
       "\n",
       "[149570 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fiction', 'fiction', 'biography autobiography', ..., 'fiction',\n",
       "       'fiction', 'computers'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y = clf.predict(_X_Vec)\n",
    "_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[~books['category'].isin(top_20_categories), 'category'] = _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('/opt/ml/data/preprocess_data/category_filled_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                       0\n",
       "book_title                 0\n",
       "book_author                1\n",
       "year_of_publication        0\n",
       "publisher                  0\n",
       "img_url                    0\n",
       "language               67227\n",
       "category                   0\n",
       "summary                67227\n",
       "img_path                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.drop(books.loc[books['book_author'].isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_count_df = pd.DataFrame(books['language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en    78823\n",
       "de     1282\n",
       "es     1017\n",
       "fr      883\n",
       "it      123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for small_lan in value_count_df[value_count_df['count'] < 100].index:\n",
    "#     books.drop(books.loc[books['language'] == small_lan].index, inplace = True)\n",
    "# books['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_books = books[books['language'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9845770842188354\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "          ca       0.00      0.00      0.00         3\n",
      "          da       0.00      0.00      0.00         8\n",
      "          de       0.96      0.84      0.90       249\n",
      "          el       0.00      0.00      0.00         1\n",
      "          en       0.99      1.00      0.99     15761\n",
      "          eo       0.00      0.00      0.00         1\n",
      "          es       0.88      0.61      0.72       217\n",
      "          fa       0.00      0.00      0.00         1\n",
      "          fr       0.88      0.73      0.80       181\n",
      "          it       1.00      0.33      0.50        27\n",
      "          nl       1.00      0.10      0.18        10\n",
      "          no       0.00      0.00      0.00         1\n",
      "          pt       1.00      0.14      0.25         7\n",
      "       zh-CN       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.98     16469\n",
      "   macro avg       0.48      0.27      0.31     16469\n",
      "weighted avg       0.98      0.98      0.98     16469\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = train_books[['book_title', 'book_author', 'publisher']]\n",
    "y = train_books['language']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train['book_title'] + ' ' + X_train['book_author'] + ' ' + X_train['publisher'])\n",
    "X_test_vec = vectorizer.transform(X_test['book_title'] + ' ' + X_test['book_author'] + ' ' + X_test['publisher'])\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "_classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('Accuracy: ', accuracy)\n",
    "print(\"Classification Report : \", _classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLEADING GUILTY</td>\n",
       "      <td>Scott Turow</td>\n",
       "      <td>Audioworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Middle Stories</td>\n",
       "      <td>Sheila Heti</td>\n",
       "      <td>House of Anansi Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>R. J. Kaiser</td>\n",
       "      <td>Mira Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A Second Chicken Soup for the Woman's Soul (Ch...</td>\n",
       "      <td>Jack Canfield</td>\n",
       "      <td>Health Communications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Witchfinder (Amos Walker Mystery Series)</td>\n",
       "      <td>Loren D. Estleman</td>\n",
       "      <td>Brilliance Audio - Trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149560</th>\n",
       "      <td>Town Like Alice</td>\n",
       "      <td>Nevil Shute</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149561</th>\n",
       "      <td>LA Muerte Del Decano</td>\n",
       "      <td>Gonzalo Torrrente Ballester</td>\n",
       "      <td>Planeta Publishing Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149564</th>\n",
       "      <td>The Motley Fool's What To Do with Your Money N...</td>\n",
       "      <td>David Gardner</td>\n",
       "      <td>Simon &amp; Schuster Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149567</th>\n",
       "      <td>Why stop?: A guide to Texas historical roadsid...</td>\n",
       "      <td>Claude Dooley</td>\n",
       "      <td>Lone Star Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149569</th>\n",
       "      <td>Dallas Street Map Guide and Directory, 2000 Ed...</td>\n",
       "      <td>Mapsco</td>\n",
       "      <td>American Map Corporation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               book_title   \n",
       "5                                         PLEADING GUILTY  \\\n",
       "8                                      The Middle Stories   \n",
       "9                                                Jane Doe   \n",
       "10      A Second Chicken Soup for the Woman's Soul (Ch...   \n",
       "11           The Witchfinder (Amos Walker Mystery Series)   \n",
       "...                                                   ...   \n",
       "149560                                    Town Like Alice   \n",
       "149561                               LA Muerte Del Decano   \n",
       "149564  The Motley Fool's What To Do with Your Money N...   \n",
       "149567  Why stop?: A guide to Texas historical roadsid...   \n",
       "149569  Dallas Street Map Guide and Directory, 2000 Ed...   \n",
       "\n",
       "                        book_author                       publisher  \n",
       "5                       Scott Turow                      Audioworks  \n",
       "8                       Sheila Heti           House of Anansi Press  \n",
       "9                      R. J. Kaiser                      Mira Books  \n",
       "10                    Jack Canfield           Health Communications  \n",
       "11                Loren D. Estleman        Brilliance Audio - Trade  \n",
       "...                             ...                             ...  \n",
       "149560                  Nevil Shute                Ballantine Books  \n",
       "149561  Gonzalo Torrrente Ballester  Planeta Publishing Corporation  \n",
       "149564                David Gardner          Simon & Schuster Audio  \n",
       "149567                Claude Dooley                 Lone Star Books  \n",
       "149569                       Mapsco        American Map Corporation  \n",
       "\n",
       "[67226 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X = books[books['language'].isna()][['book_title', 'book_author', 'publisher']]\n",
    "_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<67226x51736 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 594802 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_Vec = vectorizer.transform(_X['book_title'] + ' ' + _X['book_author'] + ' ' + _X['publisher'])\n",
    "_X_Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'en', 'en', ..., 'en', 'en', 'en'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y = clf.predict(_X_Vec)\n",
    "_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books['language'].isna(), 'language'] = _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                       0\n",
       "book_title                 0\n",
       "book_author                0\n",
       "year_of_publication        0\n",
       "publisher                  0\n",
       "img_url                    0\n",
       "language                   0\n",
       "category                   0\n",
       "summary                67226\n",
       "img_path                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('/opt/ml/data/preprocess_data/category_language_filled_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                       0\n",
       "book_title                 0\n",
       "book_author                0\n",
       "year_of_publication        0\n",
       "publisher                  0\n",
       "img_url                    0\n",
       "language                   0\n",
       "category                   0\n",
       "summary                67226\n",
       "img_path                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/4) fill country:  17%|█▋        | 360/2097 [00:09<00:46, 37.05it/s]/tmp/ipykernel_67543/690346601.py:14: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
      "(1/4) fill country:  61%|██████▏   | 1288/2097 [00:34<00:21, 37.58it/s]/tmp/ipykernel_67543/690346601.py:14: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
      "(1/4) fill country: 100%|██████████| 2097/2097 [00:55<00:00, 37.50it/s]\n",
      "(2/4) fill city: 100%|██████████| 1948/1948 [00:20<00:00, 95.53it/s]\n"
     ]
    }
   ],
   "source": [
    "users['location'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0])\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1])\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2])\n",
    "users = users.replace('na', np.nan) #특수문자 제거로 n/a가 na로 바뀌게 되었습니다. 따라서 이를 컴퓨터가 인식할 수 있는 결측값으로 변환합니다.\n",
    "users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "\n",
    "# city는 있는데 country 없는 경우 채우기\n",
    "modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "\n",
    "location_list = []\n",
    "for location in tqdm(modify_location, desc='(1/4) fill country'):\n",
    "    try:\n",
    "        right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "        location_list.append(right_location)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for location in tqdm(location_list, desc='(2/4) fill city'):\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>49.0</td>\n",
       "      <td>ottawa</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67544</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>30.0</td>\n",
       "      <td>toronto</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85526</td>\n",
       "      <td>victoria, british columbia, canada</td>\n",
       "      <td>36.0</td>\n",
       "      <td>victoria</td>\n",
       "      <td>british columbia</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68087</th>\n",
       "      <td>278376</td>\n",
       "      <td>danville, pennsylvania, usa</td>\n",
       "      <td>54.0</td>\n",
       "      <td>danville</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68088</th>\n",
       "      <td>278621</td>\n",
       "      <td>victoria, delaware, canada</td>\n",
       "      <td>74.0</td>\n",
       "      <td>victoria</td>\n",
       "      <td>delaware</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68089</th>\n",
       "      <td>278636</td>\n",
       "      <td>irvington, alabama, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>irvington</td>\n",
       "      <td>alabama</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68090</th>\n",
       "      <td>278659</td>\n",
       "      <td>vancouver, washington, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>vancouver</td>\n",
       "      <td>british columbia</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68091</th>\n",
       "      <td>278713</td>\n",
       "      <td>albuquerque, new mexico, usa</td>\n",
       "      <td>63.0</td>\n",
       "      <td>albuquerque</td>\n",
       "      <td>new mexico</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68092 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                            location   age location_city   \n",
       "0            8            timmins, ontario, canada   NaN       timmins  \\\n",
       "1        11400             ottawa, ontario, canada  49.0        ottawa   \n",
       "2        11676                       n/a, n/a, n/a   NaN           n/a   \n",
       "3        67544            toronto, ontario, canada  30.0       toronto   \n",
       "4        85526  victoria, british columbia, canada  36.0      victoria   \n",
       "...        ...                                 ...   ...           ...   \n",
       "68087   278376         danville, pennsylvania, usa  54.0      danville   \n",
       "68088   278621          victoria, delaware, canada  74.0      victoria   \n",
       "68089   278636             irvington, alabama, usa   NaN     irvington   \n",
       "68090   278659          vancouver, washington, usa  33.0     vancouver   \n",
       "68091   278713        albuquerque, new mexico, usa  63.0   albuquerque   \n",
       "\n",
       "          location_state location_country  \n",
       "0                ontario           canada  \n",
       "1                ontario           canada  \n",
       "2                    n/a              n/a  \n",
       "3                ontario           canada  \n",
       "4       british columbia           canada  \n",
       "...                  ...              ...  \n",
       "68087         california              usa  \n",
       "68088           delaware           canada  \n",
       "68089            alabama              usa  \n",
       "68090   british columbia           canada  \n",
       "68091         new mexico              usa  \n",
       "\n",
       "[68092 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67544</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123629</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200273</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210926</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306790</th>\n",
       "      <td>278843</td>\n",
       "      <td>0743525493</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306791</th>\n",
       "      <td>278851</td>\n",
       "      <td>067161746X</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306792</th>\n",
       "      <td>278851</td>\n",
       "      <td>0884159221</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306793</th>\n",
       "      <td>278851</td>\n",
       "      <td>0912333022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306794</th>\n",
       "      <td>278851</td>\n",
       "      <td>1569661057</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306795 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn  rating\n",
       "0             8  0002005018       4\n",
       "1         67544  0002005018       7\n",
       "2        123629  0002005018       8\n",
       "3        200273  0002005018       8\n",
       "4        210926  0002005018       9\n",
       "...         ...         ...     ...\n",
       "306790   278843  0743525493       7\n",
       "306791   278851  067161746X       6\n",
       "306792   278851  0884159221       7\n",
       "306793   278851  0912333022       7\n",
       "306794   278851  1569661057      10\n",
       "\n",
       "[306795 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
