{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec # numpy version 1.20.3 -> 1.24.2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "books = pd.read_csv('/opt/ml/data/books.csv')\n",
    "users = pd.read_csv('/opt/ml/data/users.csv')\n",
    "ratings1 = pd.read_csv('/opt/ml/data/train_ratings.csv')\n",
    "ratings2 = pd.read_csv('/opt/ml/data/test_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_map(x: int) -> int:\n",
    "    x = int(x)\n",
    "    if x < 20:\n",
    "        return 1\n",
    "    elif x >= 20 and x < 30:\n",
    "        return 2\n",
    "    elif x >= 30 and x < 40:\n",
    "        return 3\n",
    "    elif x >= 40 and x < 50:\n",
    "        return 4\n",
    "    elif x >= 50 and x < 60:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "    \n",
    "def year_of_publication_map(x):\n",
    "    return round(x, -1)\n",
    "    \n",
    "def replace_na(unique:np.array):\n",
    "    unique = unique.tolist()\n",
    "    unique.remove('na')\n",
    "    unique = ['na'] + unique\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67544</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85526</td>\n",
       "      <td>victoria, british columbia, canada</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68087</th>\n",
       "      <td>278376</td>\n",
       "      <td>danville, pennsylvania, usa</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68088</th>\n",
       "      <td>278621</td>\n",
       "      <td>victoria, delaware, canada</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68089</th>\n",
       "      <td>278636</td>\n",
       "      <td>irvington, alabama, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68090</th>\n",
       "      <td>278659</td>\n",
       "      <td>vancouver, washington, usa</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68091</th>\n",
       "      <td>278713</td>\n",
       "      <td>albuquerque, new mexico, usa</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                            location   age\n",
       "0            8            timmins, ontario, canada   NaN\n",
       "1        11400             ottawa, ontario, canada  49.0\n",
       "2        11676                       n/a, n/a, n/a   NaN\n",
       "3        67544            toronto, ontario, canada  30.0\n",
       "4        85526  victoria, british columbia, canada  36.0\n",
       "...        ...                                 ...   ...\n",
       "68087   278376         danville, pennsylvania, usa  54.0\n",
       "68088   278621          victoria, delaware, canada  74.0\n",
       "68089   278636             irvington, alabama, usa   NaN\n",
       "68090   278659          vancouver, washington, usa  33.0\n",
       "68091   278713        albuquerque, new mexico, usa  63.0\n",
       "\n",
       "[68092 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/4) fill country:   0%|          | 0/2097 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Mission1 EDA Start --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/4) fill country:  17%|█▋        | 363/2097 [00:10<00:52, 32.89it/s]/tmp/ipykernel_81267/955413887.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
      "(1/4) fill country:  61%|██████▏   | 1287/2097 [00:39<00:24, 33.65it/s]/tmp/ipykernel_81267/955413887.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
      "(1/4) fill country: 100%|██████████| 2097/2097 [01:03<00:00, 32.99it/s]\n",
      "(2/4) fill city: 100%|██████████| 1948/1948 [00:22<00:00, 85.23it/s]\n",
      "(3/4) grouping same publisher: 100%|██████████| 5276/5276 [03:08<00:00, 27.99it/s]\n",
      "(4/4) : high-categorizing: 100%|██████████| 43/43 [00:02<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Mission1 EDA Done --------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*20, 'Mission1 EDA Start', '-'*20)\n",
    "# user preprocessing\n",
    "users['location'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0])\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1])\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2])\n",
    "users = users.replace('na', np.nan) #특수문자 제거로 n/a가 na로 바뀌게 되었습니다. 따라서 이를 컴퓨터가 인식할 수 있는 결측값으로 변환합니다.\n",
    "users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "\n",
    "# city는 있는데 country 없는 경우 채우기\n",
    "modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "\n",
    "location_list = []\n",
    "for location in tqdm(modify_location, desc='(1/4) fill country'):\n",
    "    try:\n",
    "        right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "        location_list.append(right_location)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for location in tqdm(location_list, desc='(2/4) fill city'):\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]\n",
    "\n",
    "\n",
    "# book preprocessing\n",
    "\n",
    "# 유명 출판사 표기 오류로 그룹화되지 못하는 케이스 처리\n",
    "publisher_dict=(books['publisher'].value_counts()).to_dict()\n",
    "publisher_count_df = pd.DataFrame(list(publisher_dict.items()),columns = ['publisher','count'])\n",
    "publisher_count_df = publisher_count_df.sort_values(by=['count'], ascending = False)\n",
    "\n",
    "modify_list = publisher_count_df[publisher_count_df['count']>1].publisher.values\n",
    "\n",
    "for publisher in tqdm(modify_list, desc = '(3/4) grouping same publisher'):\n",
    "    try:\n",
    "        number = books[books['publisher']==publisher]['isbn'].apply(lambda x: x[:4]).value_counts().index[0]\n",
    "        right_publisher = books[books['isbn'].apply(lambda x: x[:4])==number]['publisher'].value_counts().index[0]\n",
    "        books.loc[books[books['isbn'].apply(lambda x: x[:4])==number].index,'publisher'] = right_publisher\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "# category 대괄호 제거 및 소문자 변환\n",
    "books.loc[books[books['category'].notnull()].index, 'category'] = books[books['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "books['category'] = books['category'].str.lower()\n",
    "\n",
    "# 43개의 high-category로 묶기\n",
    "categories = ['garden','crafts','physics','adventure','music','fiction','nonfiction','science','science fiction','social','homicide',\n",
    "                'sociology','disease','religion','christian','philosophy','psycholog','mathemat','agricult','environmental',\n",
    "                'business','poetry','drama','literary','travel','motion picture','children','cook','literature','electronic',\n",
    "                'humor','animal','bird','photograph','computer','house','ecology','family','architect','camp','criminal','language','india']\n",
    "\n",
    "for category in tqdm(categories, desc = '(4/4) : high-categorizing'):\n",
    "    books.loc[books[books['category'].str.contains(category,na=False)].index,'category_high'] = category\n",
    "\n",
    "# 10개 이하 항목 others로 묶기\n",
    "category_high_df = pd.DataFrame(books['category_high'].value_counts()).reset_index()\n",
    "category_high_df.columns = ['category','count']\n",
    "others_list = category_high_df[category_high_df['count']<10]['category'].values\n",
    "books.loc[books[books['category_high'].isin(others_list)].index, 'category_high']='others'\n",
    "\n",
    "# year_of_publication 변수 전처리\n",
    "books.loc[104259, 'year_of_publication'] = 2010.0\n",
    "books.loc[121860, 'year_of_publication'] = 1997.0\n",
    "books = books.drop(np.where(books['year_of_publication'] < 1900)[0][0]).reset_index(drop=True)\n",
    "\n",
    "# location은 이제 필요 없음\n",
    "users = users.drop(['location'], axis=1)\n",
    "print('-'*20, 'Mission1 EDA Done', '-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67544</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123629</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200273</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210926</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383489</th>\n",
       "      <td>278543</td>\n",
       "      <td>1576734218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383490</th>\n",
       "      <td>278563</td>\n",
       "      <td>3492223710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383491</th>\n",
       "      <td>278633</td>\n",
       "      <td>1896095186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383492</th>\n",
       "      <td>278668</td>\n",
       "      <td>8408044079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383493</th>\n",
       "      <td>278851</td>\n",
       "      <td>0767907566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn  rating\n",
       "0             8  0002005018       4\n",
       "1         67544  0002005018       7\n",
       "2        123629  0002005018       8\n",
       "3        200273  0002005018       8\n",
       "4        210926  0002005018       9\n",
       "...         ...         ...     ...\n",
       "383489   278543  1576734218       0\n",
       "383490   278563  3492223710       0\n",
       "383491   278633  1896095186       0\n",
       "383492   278668  8408044079       0\n",
       "383493   278851  0767907566       0\n",
       "\n",
       "[383494 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.concat([ratings1, ratings2]).reset_index(drop=True)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = ratings.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'category_high', 'publisher', 'language', 'book_author', 'year_of_publication']], on='isbn', how='left')\n",
    "train_df = ratings1.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'category_high', 'publisher', 'language', 'book_author', 'year_of_publication']], on='isbn', how='left')\n",
    "test_df = ratings2.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'category_high', 'publisher', 'language', 'book_author', 'year_of_publication']], on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['age'] = train_df['age'].fillna(int(train_df['age'].median()))\n",
    "train_df['age_map'] = train_df['age'].apply(age_map)\n",
    "test_df['age'] = test_df['age'].fillna(int(test_df['age'].median()))\n",
    "test_df['age_map'] = test_df['age'].apply(age_map)\n",
    "train_df['year_of_publication_map'] = train_df['year_of_publication'].apply(year_of_publication_map)\n",
    "test_df['year_of_publication_map'] = test_df['year_of_publication'].apply(year_of_publication_map)\n",
    "\n",
    "\n",
    "context_df = context_df.fillna('na') ; train_df = train_df.fillna('na') ; test_df = test_df.fillna('na')\n",
    "\n",
    "# 인덱싱 처리\n",
    "loc_city2idx = {v:k for k,v in enumerate(replace_na(context_df['location_city'].unique()))}\n",
    "loc_state2idx = {v:k for k,v in enumerate(replace_na(context_df['location_state'].unique()))}\n",
    "loc_country2idx = {v:k for k,v in enumerate(replace_na(context_df['location_country'].unique()))}\n",
    "\n",
    "train_df['location_city'] = train_df['location_city'].map(loc_city2idx)\n",
    "train_df['location_state'] = train_df['location_state'].map(loc_state2idx)\n",
    "train_df['location_country'] = train_df['location_country'].map(loc_country2idx)\n",
    "test_df['location_city'] = test_df['location_city'].map(loc_city2idx)\n",
    "test_df['location_state'] = test_df['location_state'].map(loc_state2idx)\n",
    "test_df['location_country'] = test_df['location_country'].map(loc_country2idx)\n",
    "\n",
    "# book 파트 인덱싱\n",
    "category2idx = {v:k for k,v in enumerate(replace_na(context_df['category'].unique()))}\n",
    "categoryhigh2idx = {v:k for k,v in enumerate(replace_na(context_df['category_high'].unique()))}\n",
    "publisher2idx = {v:k for k,v in enumerate(replace_na(context_df['publisher'].unique()))}\n",
    "language2idx = {v:k for k,v in enumerate(replace_na(context_df['language'].unique()))}\n",
    "author2idx = {v:k for k,v in enumerate(replace_na(context_df['book_author'].unique()))}\n",
    "\n",
    "train_df['category'] = train_df['category'].map(category2idx)\n",
    "train_df['category_high'] = train_df['category_high'].map(categoryhigh2idx)\n",
    "train_df['publisher'] = train_df['publisher'].map(publisher2idx)\n",
    "train_df['language'] = train_df['language'].map(language2idx)\n",
    "train_df['book_author'] = train_df['book_author'].map(author2idx)\n",
    "test_df['category'] = test_df['category'].map(category2idx)\n",
    "test_df['category_high'] = test_df['category_high'].map(categoryhigh2idx)\n",
    "test_df['publisher'] = test_df['publisher'].map(publisher2idx)\n",
    "test_df['language'] = test_df['language'].map(language2idx)\n",
    "test_df['book_author'] = test_df['book_author'].map(author2idx)\n",
    "\n",
    "idx = {\n",
    "    \"loc_city2idx\":loc_city2idx,\n",
    "    \"loc_state2idx\":loc_state2idx,\n",
    "    \"loc_country2idx\":loc_country2idx,\n",
    "    \"category2idx\":category2idx,\n",
    "    \"categoryhigh2idx\":categoryhigh2idx,\n",
    "    \"publisher2idx\":publisher2idx,\n",
    "    \"language2idx\":language2idx,\n",
    "    \"author2idx\":author2idx,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user별 평점의 [평균, 중앙값, 분산, 표준편차] feature 추가\n",
    "FE_user = context_df[['user_id', 'rating']].groupby('user_id').aggregate([np.mean, np.median, np.var, np.std]).fillna(0)\n",
    "FE_user = FE_user['rating'].rename(columns = {'mean':'mean_user', 'median':'median_user', 'var':'var_user', 'std':'std_user'})\n",
    "train_df = train_df.merge(FE_user, how = 'left', left_on='user_id', right_on = 'user_id')\n",
    "test_df = test_df.merge(FE_user, how = 'left', left_on='user_id', right_on = 'user_id')\n",
    "\n",
    "# category별 모든 유저의 평점의 [평균, 중앙값, 분산, 표준편차] feature 추가\n",
    "idx2category = {v : k for k, v in category2idx.items()}\n",
    "idx2categoryhigh = idx2category = {v : k for k, v in categoryhigh2idx.items()}\n",
    "\n",
    "tmp_context_df = train_df.copy()\n",
    "tmp_context_high_df = train_df.copy()\n",
    "tmp_context_df.index = tmp_context_df.index.map(idx2category)\n",
    "tmp_context_high_df.index = tmp_context_high_df.index.map(idx2categoryhigh)\n",
    "\n",
    "FE_category = tmp_context_df.loc[:,['category', 'rating']].groupby('category').aggregate([np.mean, np.median, np.var, np.std]).fillna(0)\n",
    "FE_category_high = tmp_context_high_df.loc[:,['category_high', 'rating']].groupby('category_high').aggregate([np.mean, np.median, np.var, np.std]).fillna(0)\n",
    "\n",
    "for agg in ['mean', 'median', 'std']:\n",
    "    train_df[f'category_{agg}'] = train_df['category'].map(FE_category.loc[:, 'rating'][agg])\n",
    "    test_df[f'category_{agg}'] = test_df['category'].map(FE_category.loc[:, 'rating'][agg])\n",
    "    train_df[f'category_high_{agg}'] = train_df['category_high'].map(FE_category_high.loc[:, 'rating'][agg])\n",
    "    test_df[f'category_high_{agg}'] = test_df['category_high'].map(FE_category_high.loc[:, 'rating'][agg])\n",
    "\n",
    "# category별 각 유저의 평점의 [평균, 중앙값, 분산, 표준편차] feature 추가\n",
    "FE_user_category = tmp_context_df.loc[:,['user_id', 'category', 'rating']].groupby(['user_id', 'category']).aggregate([np.mean, np.median, np.var, np.std]).fillna(0)\n",
    "FE_user_category_high = tmp_context_df.loc[:,['user_id', 'category_high', 'rating']].groupby(['user_id', 'category_high']).aggregate([np.mean, np.median, np.var, np.std]).fillna(0)\n",
    "\n",
    "train_df = train_df.merge(FE_user_category['rating'], how = 'left', left_on=['user_id', 'category'], right_on = ['user_id', 'category'])\\\n",
    "                   .merge(FE_user_category_high['rating'], how = 'left', left_on=['user_id', 'category_high'], right_on = ['user_id', 'category_high'], suffixes=('_user_category', '_user_category_high'))\n",
    "test_df = test_df.merge(FE_user_category['rating'], how = 'left', left_on=['user_id', 'category'], right_on = ['user_id', 'category'])\\\n",
    "                 .merge(FE_user_category_high['rating'], how = 'left', left_on=['user_id', 'category_high'], right_on = ['user_id', 'category_high'], suffixes=('_user_category', '_user_category_high'))\n",
    "\n",
    "del FE_user, tmp_context_df, tmp_context_high_df, FE_category, FE_category_high, FE_user_category, FE_user_category_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
